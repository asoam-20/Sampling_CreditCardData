{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54E0SHYZdEnG",
        "outputId": "a1910853-42e4-46ee-bef0-2baa31366ba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1792376056.py:40: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  s3 = balanced_df.groupby('Class', group_keys=False).apply(lambda x: x.sample(sample_size//2, random_state=3))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          Sampling1  Sampling2  Sampling3  Sampling4  \\\n",
            "M1 (Logistic Regression)      93.51      89.61      89.61      85.53   \n",
            "M2 (Decision Tree)            98.70      97.40      92.21     100.00   \n",
            "M3 (Random Forest)           100.00     100.00      98.70      98.68   \n",
            "M4 (SVM)                      67.53      75.32      64.94      71.05   \n",
            "M5 (KNN)                      94.81      93.51      87.01      97.37   \n",
            "\n",
            "                          Sampling5  \n",
            "M1 (Logistic Regression)      93.51  \n",
            "M2 (Decision Tree)            98.70  \n",
            "M3 (Random Forest)           100.00  \n",
            "M4 (SVM)                      72.73  \n",
            "M5 (KNN)                      93.51  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import math\n",
        "\n",
        "df = pd.read_csv('Creditcard_data.csv')\n",
        "\n",
        "\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
        "balanced_df = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "\n",
        "# Formula for Sample Size (n) based on Z-score, Margin of Error (e), and Proportion (p)\n",
        "# n = (Z^2 * p * (1-p)) / e^2\n",
        "Z = 1.96 # 95% Confidence Level\n",
        "p = 0.5\n",
        "e = 0.05\n",
        "sample_size = math.ceil((Z**2 * p * (1-p)) / (e**2))\n",
        "\n",
        "\n",
        "\n",
        "# Sample 1: Simple Random Sampling\n",
        "s1 = balanced_df.sample(n=sample_size, random_state=1)\n",
        "\n",
        "# Sample 2: Systematic Sampling\n",
        "k = len(balanced_df) // sample_size\n",
        "s2 = balanced_df.iloc[::k][:sample_size]\n",
        "\n",
        "# Sample 3: Stratified Sampling\n",
        "# We use 'Class' as the strata\n",
        "s3 = balanced_df.groupby('Class', group_keys=False).apply(lambda x: x.sample(sample_size//2, random_state=3))\n",
        "\n",
        "# Sample 4: Cluster Sampling\n",
        "cluster_size = 10\n",
        "balanced_df['Cluster'] = np.arange(len(balanced_df)) // cluster_size\n",
        "selected_clusters = np.random.choice(balanced_df['Cluster'].unique(), size=sample_size // cluster_size, replace=False)\n",
        "s4 = balanced_df[balanced_df['Cluster'].isin(selected_clusters)].drop('Cluster', axis=1)\n",
        "balanced_df.drop('Cluster', axis=1, inplace=True)\n",
        "\n",
        "# Sample 5: Bootstrap Sampling (Sampling with replacement)\n",
        "s5 = balanced_df.sample(n=sample_size, replace=True, random_state=5)\n",
        "\n",
        "samples = [s1, s2, s3, s4, s5]\n",
        "\n",
        "models = {\n",
        "    \"M1 (Logistic Regression)\": LogisticRegression(max_iter=1000),\n",
        "    \"M2 (Decision Tree)\": DecisionTreeClassifier(),\n",
        "    \"M3 (Random Forest)\": RandomForestClassifier(),\n",
        "    \"M4 (SVM)\": SVC(),\n",
        "    \"M5 (KNN)\": KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for i, sample in enumerate(samples, 1):\n",
        "    sample_accuracies = []\n",
        "    X_s = sample.drop('Class', axis=1)\n",
        "    y_s = sample['Class']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.2, random_state=42)\n",
        "\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, pred) * 100\n",
        "        sample_accuracies.append(round(acc, 2))\n",
        "\n",
        "    results[f\"Sampling{i}\"] = sample_accuracies\n",
        "\n",
        "final_table = pd.DataFrame(results, index=models.keys())\n",
        "print(final_table)"
      ]
    }
  ]
}